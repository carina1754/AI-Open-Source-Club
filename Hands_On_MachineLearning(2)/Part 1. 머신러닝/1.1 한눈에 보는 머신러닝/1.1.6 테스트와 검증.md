# 테스트와 검증
모델이 새로운 샘플에 얼마나 잘 일반화될지 아는 유일한 방법은 새로운 샘플에 실제로 적용해보는 것입니다.  
이를 위해 훈련 데이터를 <b>훈련 세트</b>와 <b>테스트 세트</b> 두개로 나눠서 진행할 수 있습니다. 훈련 세트는 모델을 훈련하기 위해 사용되고, 테스트 세트는 훈련된 모델을 실험해보기 위해 사용됩니다. 새로운 샘플에 대한 오류 비율을 <b>일반화 오차(generalization error(또는 외부 샘플 오차(out-of-sample error)</b>라고 하는데, 테스트 세트에서 모델을 평가함으로써 이 오차에 대한 추정값(estimation)을 얻고, 이는 모델이 새로운 셈플에서 얼마나 잘 작동하는지 알려줍니다. 
- 예 : 훈련 오차 낮음 but 일반화 오차가 높음 => 모델이 훈련 데이터에 과대적합됐음을 의미

## 1.1.6.1 하이퍼파라미터 튜닝과 모델 선택
모델 평가는 아주 간단한데, 그냥 테스트 세트를 사용하면 됩니다. 두 모델 중에 고민하고 있다면 바로 두 모델 모두 훈련 세트로 훈련하고 테스트 세트를 사용해 얼마나 잘 일반화되는지 비교하여 선택하면 됩니다.  

만약 일반화가 더 잘되는 모델을 선택하고 과대적합을 피하기 위해 최적의 하이퍼파라미터를 찾고 적용하고 실제 서비스에 투입했으나 예상만큼 성능이 좋지 못해 오차를 크게 만드는 경우가 발생할 수 있습니다. 이는 일반화 오차를 테스트 세트에서 여러번 측정하는 과정에서 모델이 테스트 세트에 점점 최적화가 되었기 때문입니다.   

이러한 문제에 대한 일반적인 해결방안은 다음과 같습니다. 
- <b>홀드아웃 검증(holdout validation)</b>
  - 간단하게 훈련 세트의 일부를 떼어내어 여러 후보 모델을 평가하고 가장 좋은 하나를 선택하는 방식(이때 새로운 홀드 아웃 세트를 검증 세트(validation set) or 개발 세트(development set) or 데브 세트(dev set)라고 부름)
  - 방식
    1. 줄어든 훈련세트에서 다양한 하이퍼파라미터 값을 가진 여러 모델을 훈련
    2. 검증 세트에서 가장 높은 성능을 내는 모델 선택
    3. 전체 훈련 세트에서 다시 훈련하여 최종 모델 생성
    4. 최종 모델을 테스트 세트에서 평가 및 일반화 오차 추정


- 만약에 검증 세트가 너무 작거나(모델이 정확하게 평가되지 않음) 너무 크면(후훈련 세트가 전체 훈련 세트보다 너무 작아짐)
  - 작은 검증 세트를 여러개 사용해 반복적인 <b>교차검증(cross-validation)</b>으로 해결 가능
  - 방식 
    1. 검증 세트마다 나머지 데이터에서 훈련한 모델을 해당 검증 세트에서 평가
  - 장점 : 모든 모델의 평가를 평균하여 훨씬 정확한 성능을 측정 가능
  - 단점 : 훈련 시간이 검증 세트의 개수에 비례해 증가


### 데이터 불일치
쉽게 많은 양의 훈련 데이터를 얻을 수 있어도 이 데이터가 실제 제품에 사용될 데이터를 완벽하게 대표하지 못할 수 있습니다. 이러한 상황을 데이터 불일치라고 부릅니다. 그만큼 검증 세트와 테스트 세트가 실전에서 기대하는 데이터를 가능한 잘 대표해야하는데, 이는 검증 세트와 테스트 세트에 대표 사진이 배타적으로 포함되어있어야한다는 의미이기도 합니다. 그러나 이렇게 하더라도 모델이 훈련 세트에 과대적합인지 아니면 데이터가 불일치(예로들면 웹 사진과 모바일 앱 사진의 데이터가 다른 것)하기 때문인지 알 수가 없습니다.   

한가지 해결방안은 훈련 사진의 일부를 떼어내어 또 다른 세트를 만드는 것입니다. 이를 앤드루 응이 <b>훈련-개발세트(train-dev set)</b>라고 부릅니다. 
- 방식
  1. 모델을 훈련세트에서 훈련한 후 훈련-개발 세트에서 평가
  2. 세가지 결론에 도달
     - 모델이 잘 작동한다 => 훈련 세트에 과대적합된 것이 아님
     - **검증 세트에서** 나쁜 성능을 낸다 => **데이터 불일치** 
       - 해결 방안 : 데이터들이 비슷할 수 있게 전처리한 다음 모델을 다시 훈련
     - **훈련-개발 세트에서** 잘 작동하지 않음 => **훈련 세트에 과대적합**
       - 해결 방안 : 모델을 규제하거나 더 많은 훈련 데이터를 수집하거나 훈련 데이터 정제를 시도
