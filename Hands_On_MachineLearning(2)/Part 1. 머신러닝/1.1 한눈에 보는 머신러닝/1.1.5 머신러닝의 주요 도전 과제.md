# 머신러닝의 주요 도전 과제
문제가 될 수 있는 것
1. 데이터
2. 학습 알고리즘

## 데이터 부분 문제

### <b>1.1.5.1 충분하지 않은 양의 훈련 데이터</b>
머신러닝 알고리즘은 여전히 많은 데이터를 필요로 합니다. 아주 간단한 문제에서조차도 수천 개의 데이터가 필요하고 이미지나 음성 인식 같은 복잡한 문제라면 수백만 개까지도 필요할 수 있습니다.

### <b>1.1.5.2 대표성 없는 훈련 데이터</b>
사례 기반 학습이나 모델 기반 학습 모두 일반화가 잘되려면 훈련 데이터가 잘 대표하는 것이 중요합니다. 대표성 없는 훈련 데이터를 사용하게 될 경우 정확한 예측을 하지 못하는 상황이 나오기 쉽습니다. 그래서 일반화하려는 사례들을 대표하는 훈련 세트를 사용하는 것이 중요한데, 이것조차 찾기 쉽지 않습니다.  

왜냐하면 샘플이 작으면 <b>샘플링잡음(sampling noise)</b>(우연에 의한 대표성 없는 데이터)가 생기기도 하고, 매우 큰 샘플도 표본 추출 방법에 문제가 있으면 대표성을 띠지 못해 <b>샘플링 편향(sampling bias)</b>가 발생할 수 있기 때문입니다.

### <b>1.1.5.3 낮은 품질의 데이터</b>
훈련 데이터가 에러, 이상치, 잡음으로 가득하다면 머신러닝 시스템이 데이터에 내재된 패턴을 찾기 어려워하여 잘 작동하지 않을 것입니다. 따라서 데이터의 정제에 투자할 가치는 충분하고 꼭 필요한 과정입니다.(정제되있지 않을 경우).  
다음은 훈련 데이터 정제가 필요한 상황입니다.
1. 일부 샘플이 이상치라는게 명확하다.
   - 해결 방안
   1.  간단히 그것들을 무시하거나 수동으로 잘못된 것을 고치는 것이 좋음
2. 일부 샘플에 특성 몇개가 빠져있다.
   - 해결 방안
   1. 특성을 모두 무시할지, 샘플을 무시할지, 빠진 값을 채울지, 또는 이 특성을 넣은 모델과 제외한 모델을 따로 훈련시킬 것인지 결정

### <b>1.1.5.4 관련 없는 특성</b>
머신러닝 시스템은 훈련 데이터에 관련 없는 특성이 적고 관련 있는 특성이 충분해야 시스템이 원활하게 학습할 수 있습니다. 따라서 성공적인 머신러닝 프로젝트의 핵심 요소는 훈련에 사용할 좋은 특성들을 찾는 것입니다.  
이 과정을 <b>특성 공학(feature engineering)</b>이라 하며 다음과 같은 작업을 거칩니다.
- 특성 선택(feature selection) : 가지고 있는 특성 중에서 훈련에 가장 유용한 특성을 선택
- 특성 추출(feature extraction) : 특성을 결합하여 더 유용한 특성을 만듭니다. 앞서 본 것처럼 차원 축소 알고리즘이 도움이 될 수 있음
- 새로운 데이터를 수집해 새 특성을 생성

## 학습 알고리즘 부분 문제
### <b>1.1.5.5 훈련 데이터 과대적합</b>
사람이 종종 과도하게 일반화를 하는 것처럼 머신러닝 시스템도 마찬가지로 주의하지 않으면 똑같은 짓을 저질 수 있습니다. 이를 <b>과대적합(overfiting)</b>이라고 하며, 모델이 훈련 데이터에는 너무 잘 맞으나 일반성이 떨어질때를 의미합니다.  

과대적합은 훈련 데이터에 있는 잡음의 양에 비해 모델이 너무 복잡할 때 발생하는데, 해결 방법은 다음과 같습니다.
- 파라미터 수가 적은 모델을 선택(고차원 다항 모델 -> 선형 모델) or 훈련 데이터에있는 특성 수 줄이기 or 모델에 제약을 가하여 단순화
- 훈련 데이터를 더 많이 수집
- 훈련 데이터의 잡음을 감소(오류 데이터 수정과 이상치 제거)

모델을 단순하게 하고 과대적합의 위험을 감소시키기 위해 모델에 제약을 가하는 것을 <b>규제(regularization)</b>